{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# JudoBot (JB): A Reinforcement Learning Agent For Basic Judo Mechanics\n## (I suck at Judo so I trained a computer to do it for me)\n*by MaryLena Bleile*\n\nI have trained a reinforcement learning agent to play Judo using a basic simulated environment. The environment mechanics include gripping, stance, stamina, and win conditions between a \"Tori\" (self) and an \"Uke\" (opponent). It does not currently differentiate between specific throws (e.g. Seioi Nage, Tai otoshi), but broadly categorizes throws as North-South (NS, typically resulting in a fall to the back) and East-West (EW, resulting in a fall to the side). \n","metadata":{}},{"cell_type":"markdown","source":"North-South throws could look like this:\n\n\n![frontthrow.gif](attachment:b7f83a91-5d98-477f-8a72-124773ab6e26.gif)\n\n\n\nEast-West throws could look like this:\n\n<img src=\"attachment:b87a588e-b378-4053-bc17-e8f612a92661.jpeg\" width=\"400px\" height=\"400px\">","metadata":{},"attachments":{"b7f83a91-5d98-477f-8a72-124773ab6e26.gif":{"image/gif":"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"},"b87a588e-b378-4053-bc17-e8f612a92661.jpeg":{"image/jpeg":"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"}}},{"cell_type":"markdown","source":"**Bonus** \n\nMe doing a front throw on a spanish national heavyweight champ :)\n\n(Please copy and paste link into a new tab: Clicking directly may throw error)\n\n[https://marylenableile.com/img/VID_120030528_232102_149.mp4](https://)","metadata":{}},{"cell_type":"markdown","source":"## Library imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport itertools\nfrom functools import reduce\nimport operator\nimport os\nimport matplotlib.patches as patches\nimport matplotlib.pyplot as plt\n# global variables","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T23:08:44.088490Z","iopub.execute_input":"2025-07-16T23:08:44.088954Z","iopub.status.idle":"2025-07-16T23:08:44.094645Z","shell.execute_reply.started":"2025-07-16T23:08:44.088921Z","shell.execute_reply":"2025-07-16T23:08:44.093627Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Environment class\n\n\nThe JudoBot simulation environment is a stylized, discrete-time model of tactical interactions in Judo. Each state encodes a configuration of grip control, stance, fatigue, and game status for both the agent (Tori) and its opponent (Uke). The state space is defined as a Cartesian product of the following variables:\n\n - **Self grip** (left, right): {0, 1}\n\n- **Opponent grip** (left, right): {0, 1}\n\n- **Self stance**: {right, square, left}\n\n- **Opponent stance**: {right, square, left}\n\n - **Self fatigue**: {0, 1}\n\n- **Opponent fatigue**: {0, 1}\n\n- **Game outcome**: {-1, 0, 1} (loss, ongoing, win)\n\nEach episode begins in a neutral state and proceeds for a maximum of T rounds. During each round, the opponent first takes an action from a fixed or stochastic policy, and then the agent chooses its action. Legal actions include movement, gripping, breaking grips, and executing throws. Fatigue stats (0 or 1) and stamina (0 to 20) are tracked separately from one another: If a player is fatigued, then throw effectiveness is reduced. \n\n### Main mechanistic functions\n\n**get_valid_actions()**\nSome actions can only be attempted in specific states. For example, \"breakgripL\", corresponding to breaking uke's left grip, is only available if uke has a left grip. Similarly, throws cannot be attempted with no grips. The \"get valid action\" function retrieves the valid actions that JB can take, while \"get valid opp actions\" retrieves the valid actions that uke (the opponent) can take.\n\n**giveReward()**\nThe environment rewards are sparse: +1 for victory, -1 for loss, and 0 otherwise. Loss occurs if uke throws JB or if the episode times out without no throws. giveReward function retrieves the reward status from the state. This function could be elaborated upon if we desired, for example, to give intermediary rewards for successful grips and such.\n\n\n**_build_throw_success_table()**\nSuccess of JB's throws is determined via a probabilistic lookup table conditioned on stance, fatigue, and grip configuration; this table is constructed once upon environment class initiation using the function _build_throw_success_table(). Starting the function name with an underscore makes it an \"internal\" function to the object class. \n\n**apply_opp_action()**\nThis function modifies the state based on uke's action. For simplicity, uke's throw success is deterministic: if uke has both hands on, throws always succeed. However, uke chooses actions randomly. This loosely represents the case where uke is a true black belt who is choosing to \"play down\" his/her skills so that JB can learn.  \n\n\n**nxtPosition()**\nThis function applies the state transition dynamics. JB moves first, then uke. We first check what valid actions exist in the state using get_valid_actions function, then JB picks what it thinks is the best one out of those values. Next, the opponent's valid actions are found using get_valid_opp_actions, and the action is chosen randomly from that valid action set. The opponent's action is applied using apply_opp_action.\n\n**reset()**\nThis function resets the environment to default state with no grips and right-foot-forward stance for both players. It will be called in training at the end of each episode (game).\n\n### Helper functions\n\n**visualize_state()**\nWe visualize what JB is doing by creating an annotated cartoon depiction of each state. This function creates the plot for each specific state and saves it to a directory. At the end, we can knit them all together into a stop-motion animation.\n\n**_qualitative_throw_label()**\nThis is a helper function for translating numeric probabilities to human-readable labels. For now, JB's throws can have low, medium, or high probability of success. This is another internal function, called only by _build_throw_success_table().\n\n**get_index()**\nThis function retrieves the state element index from the state name. For example whether or not JB has left grip  (\"SelfLeftGrip\") is the first element in the state vector, so get_index(\"SelfLeftGrip\") returns the value 0. This function is not completely necessary, but I find it is helpful for making the code more readable.\n","metadata":{}},{"cell_type":"code","source":"##Define environment class\nclass Env:\n    def __init__(self):\n\n        GRIPSL = [0,1]\n        GRIPSR = [0,1]\n        GRIPOL = [0,1]\n        GRIPOR = [0,1]\n        #0: right, 1: square, 2: left\n        #S: Self, O: Opponent\n        STANCES = [0,1,2]\n        STANCEO = [0,1,2]\n        GAME_WON = [-1,0,1]\n        FATIGUES = [0,1]\n        FATIGUEO = [0,1]\n        \n        STATE_ELEMS = [GRIPSL, GRIPSR, GRIPOL, GRIPOR,STANCES, STANCEO, FATIGUES, FATIGUEO, GAME_WON]\n        STATE_NAMES = [\"SelfLeftGrip\", \"SelfRightGrip\", \"OppLeftGrip\",\"OppRightGrip\",\"SelfStance\",\"OppStance\",\"SelfFatigue\",\"OppFatigue\",\"GameWin\"]\n        self.stateidx = {name: i for i, name in enumerate(STATE_NAMES)}\n        #start with no grips or anything\n        self.START = np.zeros(len(STATE_NAMES))\n        self.STM_DIM = reduce(operator.mul, map(len, STATE_ELEMS))\n        self.state          = self.START\n        self.step_counter  = 0\n        self.agent_stamina  = 20\n        self.opp_stamina    = 20\n        self.isEnd          = False\n        self.max_steps = 10\n        self.opp_actions = [\"gripL\", \"gripR\", \"breakgripL\",\"breakgripR\", \"mv\",\"throwEW\", \"throwNS\"]\n        self._throw_success_table = self._build_throw_success_table()\n\n        # build helpers\n        self.stm_key    = pd.DataFrame(list(itertools.product(*STATE_ELEMS)),\n                                       columns=STATE_NAMES)\n        self._tuple2idx = {tuple(row): i for i, row\n                           in enumerate(self.stm_key.values)}\n\n        # Opponentâ€™s random action set  (very small & simple, expand later)\n        #self.opp_actions = [\"noop\", \"breakgrip\", \"gripL\", \"gripR\", \"mv\"]\n\n\n    def reset(self):\n        self.state          = self.START\n        self.step_counter  = 0\n        self.agent_stamina  = 20\n        self.opp_stamina    = 20\n        self.isEnd          = False\n        \n    def giveReward(self):\n        return self.state[self.stateidx[\"GameWin\"]]\n        \n\n    def get_index(self, s):\n        return self._tuple2idx[tuple(s.astype(int))]\n\n    def get_valid_actions(self, actions_list):\n        valid = [\"mv\"]\n        stance = self.state[self.stateidx[\"SelfStance\"]]\n        L_grip = self.state[self.stateidx[\"SelfLeftGrip\"]]\n        R_grip = self.state[self.stateidx[\"SelfRightGrip\"]]\n        O_Lgrip = self.state[self.stateidx[\"OppLeftGrip\"]]\n        O_Rgrip = self.state[self.stateidx[\"OppRightGrip\"]]\n        any_grip = (L_grip == 1 or R_grip == 1)\n    \n        if any_grip:\n            valid.append(\"throwNS\")\n            valid.append(\"throwEW\")\n        if O_Lgrip==1:\n            valid.append(\"breakgripL\")\n        if O_Rgrip==1:\n            valid.append(\"breakgripR\")\n        if L_grip ==0:\n            valid.append(\"gripL\")\n        if R_grip == 0:\n            valid.append(\"gripR\")\n        return valid\n        \n    def _qualitative_throw_label(self, stance, f_self, f_opp, grips):\n        both_grip = grips == \"Both\"\n        any_grip  = grips in [\"Left\", \"Right\", \"Both\"]\n\n        def label(t):\n            if both_grip or (f_opp and not f_self):\n                return \"High\"\n            if f_opp or not f_self:\n                if t == \"throwNS\" and stance == 1 and any_grip:\n                    return \"Medium\"\n                if t == \"throwEW\" and stance == 0 and grips == \"Right\":\n                    return \"Medium\"\n            return \"Low\"\n        return {t: label(t) for t in [\"throwNS\", \"throwEW\"]}\n\n    def _build_throw_success_table(self):\n\n        stances = [0, 1, 2]                  # right, square, left\n        fatigue = [0, 1]                     # 0 = fresh, 1 = fatigued\n        grips   = [\"None\", \"Left\", \"Right\", \"Both\"]\n        throws  = [\"throwNS\", \"throwEW\"]\n\n        prob_map = {\"Low\": 0.1, \"Medium\": 0.5, \"High\": 0.9}\n\n        table = {}\n        for st in stances:\n            for f_self in fatigue:\n                for f_opp in fatigue:\n                    for g in grips:\n                        labels = self._qualitative_throw_label(st, f_self, f_opp, g)\n                        for t in throws:\n                            key = (st, f_self, f_opp, g, t)\n                            table[key] = prob_map[labels[t]]\n        return table\n        \n    def get_valid_opp_actions(self, actions_list):\n        valid = [\"mv\"]\n        stance = self.state[self.stateidx[\"OppStance\"]]\n        L_grip = self.state[self.stateidx[\"OppLeftGrip\"]]\n        R_grip = self.state[self.stateidx[\"OppRightGrip\"]]\n        Tori_Lgrip = self.state[self.stateidx[\"SelfLeftGrip\"]]\n        Tori_Rgrip = self.state[self.stateidx[\"SelfRightGrip\"]]\n        any_grip = (L_grip == 1 or R_grip == 1)\n    \n        if any_grip:\n            valid.append(\"throwNS\")\n            valid.append(\"throwEW\")\n        if Tori_Lgrip==1:\n            valid.append(\"breakgripL\")\n        if Tori_Rgrip==1:\n            valid.append(\"breakgripR\")\n        if L_grip ==0:\n            valid.append(\"gripL\")\n        if R_grip == 0:\n            valid.append(\"gripR\")\n            \n            \n        return valid\n\n\n    def apply_opp_action(self, action):\n        state = self.state.copy()\n    \n        if action == \"mv\":\n            state[self.stateidx[\"OppStance\"]] = (state[self.stateidx[\"OppStance\"]] + 1) % 3\n    \n        elif action == \"gripL\":\n            state[self.stateidx[\"OppLeftGrip\"]] = 1\n    \n        elif action == \"gripR\":\n            state[self.stateidx[\"OppRightGrip\"]] = 1\n    \n        elif action == \"breakgripL\":\n            state[self.stateidx[\"SelfLeftGrip\"]] = 0\n    \n        elif action == \"breakgripR\":\n            state[self.stateidx[\"SelfRightGrip\"]] = 0\n    \n        elif \"throw\" in action:\n            # Implement opponent throw logic \n            stance = state[self.stateidx[\"OppStance\"]]\n            L_grip = state[self.stateidx[\"OppLeftGrip\"]] ==1\n            R_grip = state[self.stateidx[\"OppRightGrip\"]] ==1\n            T_Lgrip = state[self.stateidx[\"SelfLeftGrip\"]] == 1\n            T_Rgrip = state[self.stateidx[\"SelfRightGrip\"]] == 1\n    \n            any_grip = (L_grip or R_grip)\n            both_grip = (L_grip and R_grip)\n            T_no_grip = (not T_Rgrip ) and (not T_Lgrip)\n            throwsuccess = False\n    \n            if both_grip or ((state[self.stateidx[\"OppFatigue\"]] == 0) and (state[self.stateidx[\"SelfFatigue\"]]==1)):\n                throwsuccess = True\n            elif state[self.stateidx[\"OppFatigue\"]] == 0 or (state[self.stateidx[\"SelfFatigue\"]]==1):\n                    if stance == 1 and any_grip and action == \"throwNS\":\n                        throwsuccess = True\n                    elif stance == 0 and (state[self.stateidx[\"OppRightGrip\"]] == 1) and (( state[self.stateidx[\"SelfLeftGrip\"]]  == 0) or (state[self.stateidx[\"SelfRightGrip\"]] == 0)):\n                        throwsuccess = True\n                \n            \n    \n            if throwsuccess:\n                state[self.stateidx[\"GameWin\"]] = -1  # opponent wins = agent loses\n            else:\n                self.opp_stamina -= 4\n    \n        self.opp_stamina -= 0.5\n        if self.opp_stamina < 15:\n                state[self.stateidx[\"OppFatigue\"]] = 1\n        self.state = state\n\n    \n\n    def nxtPosition(self, action, return_index=False, visualize=False, step=None):\n        \n            \n\n         # If uke has just won, stop here\n        if self.isEnd:                        # (note: self.isEnd, not self.isEND)\n            if return_index:\n                return self.get_index(self.state)\n            return self.state.copy()\n        else:\n            s = self.state.copy()       # local alias\n    \n            # Gripping\n            has_left  = s[self.stateidx[\"SelfLeftGrip\"]]  == 1\n            has_right = s[self.stateidx[\"SelfRightGrip\"]] == 1\n            stance = s[self.stateidx[\"SelfStance\"]]\n            any_grip  = has_left or has_right\n            both_grip = has_left and has_right\n            if action == \"gripL\":  s[self.stateidx[\"SelfLeftGrip\"]]  = 1\n            elif action == \"gripR\":  s[self.stateidx[\"SelfRightGrip\"]] = 1\n            elif action == \"breakgripL\":  # break *uke* grips\n                s[self.stateidx[\"OppLeftGrip\"]]  = 0\n            elif action== \"breakgripR\":\n                s[self.stateidx[\"OppRightGrip\"]] = 0\n            elif action == \"mv\":     # agent stance cycle\n                s[self.stateidx[\"SelfStance\"]] = (s[self.stateidx[\"SelfStance\"]] + 1) % 3\n    \n            elif action.startswith(\"throw\"):\n                # Throw mechanics\n\n                stance  = self.state[self.stateidx[\"SelfStance\"]]\n                f_self  = self.state[self.stateidx[\"SelfFatigue\"]]\n                f_opp   = self.state[self.stateidx[\"OppFatigue\"]]\n                grip_status = (\n                    \"Both\"  if self.state[self.stateidx[\"SelfLeftGrip\"]]  and self.state[self.stateidx[\"SelfRightGrip\"]] else\n                    \"Left\"  if self.state[self.stateidx[\"SelfLeftGrip\"]]  else\n                    \"Right\" if self.state[self.stateidx[\"SelfRightGrip\"]] else\n                    \"None\"\n                )\n    \n                p = self._throw_success_table[(stance, f_self, f_opp, grip_status, action)]\n                throwsuccess = np.random.rand() < p\n                if throwsuccess:\n                    s[self.stateidx[\"GameWin\"]] = 1\n                else:\n                        # failed throw  -> stamina hit, but still alive\n                    self.agent_stamina -= 4\n    \n            self.agent_stamina -= 0.5\n            # check fatigue level: if less than 15 tori is fatigued\n            if self.agent_stamina < 15:\n                s[self.stateidx[\"SelfFatigue\"]] = 1\n    \n\n            #tori loses if s/he runs out of stamina or if the round times out\n            self.step_counter += 1\n            if self.agent_stamina <= 0 or self.step_counter > self.max_steps:\n                s[self.stateidx[\"GameWin\"]] = -1                       # loss\n\n            self.state = s\n            if self.state[self.stateidx[\"GameWin\"]] != 0 or self.step_counter > self.max_steps:\n                self.isEnd = True\n\n        if return_index:\n            return self.get_index(s)\n        opp_actions = self.get_valid_opp_actions(self.opp_actions)\n        if opp_actions:\n            opp_action = np.random.choice(opp_actions)\n            self.apply_opp_action(opp_action)\n            if self.state[self.stateidx[\"GameWin\"]] == -1:\n                self.isEnd = True\n        else:\n            print(\"OPPONENT CANNOT MOVE\")\n        if visualize:\n                self.visualize_state(\n                    action=action,\n                    opp_action = opp_action,\n                    step_num=step\n                )\n        return self.state\n\n\n    def visualize_state(self, action=None, opp_action=None, episode_num=0, step_num=0, save_dir=\"frames2\"):\n        os.makedirs(save_dir, exist_ok=True)\n    \n        state= self.state\n        SL, SR = state[self.stateidx[\"SelfLeftGrip\"]], state[self.stateidx[\"SelfRightGrip\"]]\n        ST = int(state[self.stateidx[\"SelfStance\"]])\n        FAT = state[self.stateidx[\"SelfFatigue\"]]\n        WIN = int(state[self.stateidx[\"GameWin\"]])\n    \n        OL, OR = state[self.stateidx[\"OppLeftGrip\"]], state[self.stateidx[\"OppRightGrip\"]]\n        OT = int(state[self.stateidx[\"OppStance\"]])\n        OFAT = state[self.stateidx[\"OppFatigue\"]]\n    \n        fig, ax = plt.subplots(figsize=(6,4))\n        fig.set_size_inches(4.84, 3.62)\n        ax.set_xlim(0, 10)\n        ax.set_ylim(0, 6)\n        ax.axis('off')\n        ax.set_title(f\"Episode {self.episode_num}, Step {step_num}\\nAction: {action}\", fontsize=10)\n    \n        # Draw self\n        cx, cy = 3, 3\n        ax.add_patch(patches.Circle((cx, cy), 0.5, color='lightblue'))\n        if SL: ax.plot(cx - 0.5, cy + 0.4, 'bo')\n        if SR: ax.plot(cx + 0.5, cy + 0.4, 'bo')\n        if ST == 0:\n            ax.plot([cx + 0.25], [cy - 0.7], 'ro')\n            ax.plot([cx - 0.25], [cy - 1.0], 'ro')\n        elif ST == 1:\n            ax.plot([cx - 0.3, cx + 0.3], [cy - 0.9, cy - 0.9], 'ro')\n        elif ST == 2:\n            ax.plot([cx - 0.25], [cy - 0.7], 'ro')\n            ax.plot([cx + 0.25], [cy - 1.0], 'ro')\n        if FAT: ax.text(cx, cy - 1.5, \"FATIGUE :(\", ha='center')\n    \n        # Draw opponent\n        ocx, ocy = 7, 3\n        ax.add_patch(patches.Circle((ocx, ocy), 0.5, color='salmon'))\n        if OL: ax.plot(ocx + 0.5, ocy + 0.4, 'bo')\n        if OR: ax.plot(ocx - 0.5, ocy + 0.4, 'bo')\n        if OT == 0:\n            ax.plot([ocx - 0.25], [ocy - 0.7], 'ro')\n            ax.plot([ocx + 0.25], [ocy - 1.0], 'ro')\n        elif OT == 1:\n            ax.plot([ocx - 0.3, ocx + 0.3], [ocy - 0.9, ocy - 0.9], 'ro')\n        elif OT == 2:\n            ax.plot([ocx + 0.25], [ocy - 0.7], 'ro')\n            ax.plot([ocx - 0.25], [ocy - 1.0], 'ro')\n        if OFAT: ax.text(ocx, ocy - 1.5, \"FATIGUE :)\", ha='center')\n    \n        # Show throw\n        if action and \"throw\" in action:\n            ax.text(5, 4.5, \"XXX THROW XXX\", fontsize=20, ha='center')\n    \n        # Show victory/defeat\n        if WIN == 1:\n            ax.text(5, 1.0, \"Victory!\", ha='center', fontsize=12, color='green')\n        elif WIN == -1:\n            ax.text(5, 1.0, \"Defeat\", ha='center', fontsize=12, color='red')\n    \n        # Show opponent action\n        if opp_action:\n            ax.text(ocx, ocy + 1.2, f\"Uke: {opp_action}\", ha='center', fontsize=9, color='darkred')\n    \n        fname = os.path.join(self.save_dir, f\"ep{episode_num:03d}_s{step_num:02d}.png\")\n        plt.savefig(fname, bbox_inches='tight')\n        plt.close()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T23:08:44.169146Z","iopub.execute_input":"2025-07-16T23:08:44.169468Z","iopub.status.idle":"2025-07-16T23:08:44.220013Z","shell.execute_reply.started":"2025-07-16T23:08:44.169447Z","shell.execute_reply":"2025-07-16T23:08:44.218527Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Agent class \n\nThe agent class configures and executes the learning process. Agent can be initialized with flexible training parameters:\n* min_eps: Minimum threshold on exploration rate - keeping this > 0 during training ensures measurability of the action space.\n* alpha: Learning rate. Higher values cause JB to assign more meaning to rewards at each timepoint. If success was not deterministic, meaning that hrows either always succeed or always fail in certain cases, then we would set the learning rate to 0.99 or something very close to 1.\n* gamma: Discount factor (should be 0 < gamma < 1) which calibrates the amount of importance JB assigns to short-term vs long-term rewards.\n\nUpon initialization, the agent class also constructs a Q-table representing the \"goodness\" of each state-action combination. Values in this table are subsequently based on the agent's experience.\n\nThe agent chooses actions using **choose_action()** function. We use epsilon-greedy exploration, which means that the agent will choose what it thinks is the best action according to Q table with probability 1-epsilon, and a random action otherwise. Takes as input the current state index s_idx. A testing version also exists, which is the same except there is no chance of taking a random action. \n\n**run_episode()** is the most important function on this object. This function runs a single \"game\" of Judo, for up to a prespecified number of rounds (max_steps attribute of Env, set here to 10), after which the game \"times out\". The run_episode function is written as follows: First, we reset the environment using env.reset(). Then, for each step from 1 to env.max_steps, JB applies an action and observes the resulting environment change, as implemented in env.nxtPosition(). Note that the opponent's action is part of the \"environment\" from JB's perspective: as such, the opponent action and state updated is encoded into the nxtPosition environment updated. After that, JB's internal \"belief\" about the goodness of each state-action pair, as quantified in the Q table. The update rule for Q table elements is where the Reinforcement Learning magic happens; this is indicated in the comment surrounding the update rule :) \n\n**run_test_episode*()* is the same as run_episode with two exceptions: i) is no Q-update and ii) actions are chosen completely deterministically according to the learned policy Q. This function is used for additional plays for validation and visualization once learning is complete.","metadata":{}},{"cell_type":"code","source":"\nclass Agent:\n    def __init__(self, min_eps=0.1,gamma=0.99, alpha=0.1, eps_decay = 0.9995):\n\n        self.actions = [\"gripL\", \"gripR\", \"breakgripL\",\"breakgripR\", \"mv\",\"throwEW\", \"throwNS\"]\n\n        self.n_actions = len(self.actions)\n        self.Env = Env()                       # fresh environment\n        self.Q = np.zeros((self.Env.STM_DIM, self.n_actions))   # Q-table\n        self.eps = 1\n        self.min_eps = min_eps # exploration prob\n        self.alpha = alpha\n        self.gamma = gamma\n        self.eps_decay = eps_decay\n\n        # bookkeeping for plots\n        self.rewards   = []\n        self.win_flags = []\n\n    def choose_action_test(self, s_idx):\n        valid_actions = self.Env.get_valid_actions(self.actions)\n        \n        if not valid_actions:\n            print(\"NO VALID ACTIONS\") #should never be hit\n            return np.random.choice(self.actions)  \n    \n        best_val = float(\"-inf\")\n        best_action = None\n        for a in valid_actions:\n            a_idx = self.actions.index(a)\n            val = self.Q[s_idx, a_idx]\n            if val > best_val:\n                best_val = val\n                best_action = a\n        a_str = best_action\n    \n        return self.actions.index(a_str)\n               # exploit\n    def choose_action(self, s_idx):\n        valid_actions = self.Env.get_valid_actions(self.actions)\n    \n        if not valid_actions:\n            print(\"NO VALID ACTIONS\")\n            return np.random.choice(self.actions)  \n    \n        if np.random.rand() < self.eps:\n            a_str = np.random.choice(valid_actions)\n        else:\n            best_val = float(\"-inf\")\n            best_action = None\n            for a in valid_actions:\n                a_idx = self.actions.index(a)\n                val = self.Q[s_idx, a_idx]\n                if val > best_val:\n                    best_val = val\n                    best_action = a\n            a_str = best_action\n    \n        return self.actions.index(a_str)\n               # exploit\n\n    # single training episode\n    def run_episode(self, episode_num=None, visualize=False, save_dir=\"frames\"):\n        self.Env.reset() # reset env & counters\n        if visualize:\n            os.makedirs(save_dir, exist_ok=True)\n            self.Env.save_dir= save_dir\n            self.Env.episode_num = episode_num\n        ep_reward = 0\n        for step in range(self.Env.max_steps):\n            s_idx = self.Env.get_index(self.Env.state)\n            a_idx = self.choose_action(s_idx)\n            action = self.actions[a_idx]\n\n            # take the action\n            next_state = self.Env.nxtPosition(action, visualize=visualize, step=step)\n\n            \n            s2_idx = self.Env.get_index(next_state)\n            r = self.Env.giveReward()\n\n            # do the fancy Q learning magic here :) :) \n            best_next = np.max(self.Q[s2_idx])\n            td_target = r + self.gamma * best_next\n            td_error  = td_target - self.Q[s_idx, a_idx]\n            self.Q[s_idx, a_idx] += self.alpha * td_error\n\n\n            ep_reward += r\n            \n            self.isEnd = (self.Env.state[self.Env.stateidx[\"GameWin\"]] != 0)\n            if self.Env.isEnd:\n                break                                      # terminal state\n\n        # episode-level bookkeeping\n        self.rewards.append(ep_reward)\n        self.win_flags.append(1 if self.Env.giveReward() == 1 else 0)\n\n        # eps decay\n        self.eps = max(self.min_eps, self.eps * self.eps_decay)\n        \n    def run_test_episode(self, episode_num=None, visualize=False, save_dir=\"frames\"):\n        self.Env.reset()# reset env & counters\n        if visualize:\n            os.makedirs(save_dir, exist_ok=True)\n            self.Env.save_dir= save_dir\n            self.Env.episode_num = episode_num\n        ep_reward = 0\n        for step in range(self.Env.max_steps):\n            s_idx = self.Env.get_index(self.Env.state)\n            a_idx = self.choose_action_test(s_idx)\n            action = self.actions[a_idx]\n\n            # take the action\n            next_state = self.Env.nxtPosition(action, visualize=visualize, step=step)\n\n            \n            s2_idx = self.Env.get_index(next_state)\n            r = self.Env.giveReward()\n\n            # skip Q update step\n            \n\n\n            ep_reward += r\n\n            self.Env.isEnd = (self.Env.state[self.Env.stateidx[\"GameWin\"]] != 0)\n            if self.Env.isEnd:\n                break                                      # terminal state\n\n        # episode-level bookkeeping\n        self.rewards.append(ep_reward)\n        self.win_flags.append(1 if self.Env.giveReward() == 1 else 0)\n\n        # no eps decay\n        #self.eps = max(self.min_eps, self.eps * EPS_DECAY)\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T23:08:44.222317Z","iopub.execute_input":"2025-07-16T23:08:44.222652Z","iopub.status.idle":"2025-07-16T23:08:44.252581Z","shell.execute_reply.started":"2025-07-16T23:08:44.222624Z","shell.execute_reply":"2025-07-16T23:08:44.250634Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training engine\n\nHere we define wrapper functions to train the agent and plot reward curves. This should be fairly self-explanatory.","metadata":{}},{"cell_type":"code","source":"def train(agent, episodes=500, visualize=False, save_dir=\"frames\", verbose=True):\n    for ep in range(episodes):\n        agent.run_episode(episode_num=ep, visualize=visualize, save_dir=save_dir)\n        if (ep+1) % 50 == 0 and verbose:\n            print(f\"Episode {ep+1:4d} | \"\n                  f\"eps={agent.eps:.3f} | \"\n                  f\"avg-reward(last 50)={np.mean(agent.rewards[-50:]):.3f}\")\n\ndef plot_curves(agent, smooth=10, fname='learning_curve.png', test_start_iteration=None):\n    rwd = np.array(agent.rewards)\n    win = np.array(agent.win_flags)\n    # simple moving average\n    def smooth_arr(arr, k):  \n        return np.convolve(arr, np.ones(k)/k, mode='valid')\n\n    plt.figure(figsize=(10,4))\n    plt.plot(smooth_arr(rwd, smooth), color = \"black\",label=f'Avg rewards (k={smooth})')\n    plt.legend(loc=\"center left\")\n    plt.twinx()\n    plt.plot(smooth_arr(win, smooth), 'b-', label=f'Win rate (k={smooth})')\n    if test_start_iteration is not None:\n        plt.axvline(x=test_start_iteration, color='green', linestyle='--', alpha=0.7, \n                       label=f'Testing starts (episode {test_start_iteration})')\n    plt.title('Learning curve')\n    plt.xlabel('Episode')\n    plt.legend(loc='upper left')\n    plt.grid(alpha=.3)\n    plt.savefig(fname, dpi=150, bbox_inches='tight')\n    plt.show()\n    print(f\"plot saved to {fname}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T23:08:44.253849Z","iopub.execute_input":"2025-07-16T23:08:44.254188Z","iopub.status.idle":"2025-07-16T23:08:44.272597Z","shell.execute_reply.started":"2025-07-16T23:08:44.254161Z","shell.execute_reply":"2025-07-16T23:08:44.271232Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def test(agent, episodes=500, visualize=False, save_dir=\"frames\", verbose=True):\n    for ep in range(episodes):\n        agent.run_test_episode(episode_num=ep, visualize=visualize, save_dir=save_dir)\n        if (ep+1) % 50 == 0 and verbose:\n            print(f\"Test Episode {ep+1:4d} | \"\n                  f\"eps={agent.eps:.3f} | \"\n                  f\"avg-reward(last 50)={np.mean(agent.rewards[-50:]):.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T23:08:44.274093Z","iopub.execute_input":"2025-07-16T23:08:44.274454Z","iopub.status.idle":"2025-07-16T23:08:44.299746Z","shell.execute_reply.started":"2025-07-16T23:08:44.274428Z","shell.execute_reply":"2025-07-16T23:08:44.298323Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train Agent\n\nHere we initialize the Agent class and train it. Note that the agent calls the environment class internally, so we do not need to manually specify it. Some Reinforcement Learning configurations prefer to keep these seperate for maximum flexibility, but I am lazy, so. ","metadata":{}},{"cell_type":"code","source":"np.random.seed(2001)\n\nagent = Agent(min_eps=0.1,gamma=0.99, alpha=0.5, eps_decay = 0.9995)\nepisodes=3000\ntrain(agent, episodes=episodes)\n\nagent.eps=0\nagent.min_eps =0\ntest(agent, episodes=1000)\nplot_curves(agent, smooth=50, test_start_iteration = episodes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T23:08:44.302218Z","iopub.execute_input":"2025-07-16T23:08:44.302643Z","iopub.status.idle":"2025-07-16T23:08:46.396065Z","shell.execute_reply.started":"2025-07-16T23:08:44.302594Z","shell.execute_reply":"2025-07-16T23:08:46.395035Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Plotting the reward curve we see that JB has moderate success learning to throw uke :)","metadata":{}},{"cell_type":"markdown","source":"## Visualization\nLet's see what JB is doing. We will turn the visualizer on and have JB play some more rounds.","metadata":{}},{"cell_type":"code","source":"agent.eps=0\ntest(agent, episodes=10, visualize=True,save_dir=\"frames7\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T23:08:46.397640Z","iopub.execute_input":"2025-07-16T23:08:46.398073Z","iopub.status.idle":"2025-07-16T23:08:52.427704Z","shell.execute_reply.started":"2025-07-16T23:08:46.398038Z","shell.execute_reply":"2025-07-16T23:08:52.426758Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import glob\nimport numpy as np\nimport imageio.v2 as imageio\nimport os\n\nframe_dir = \"/kaggle/working/frames7\"\nframe_paths = sorted(glob.glob(os.path.join(frame_dir, \"ep*_s*.png\")))\nprint(f\"Found {len(frame_paths)} frames\")\n\ndef pad_even(img):\n    h, w = img.shape[:2]\n    pad_h = (2 - h % 2) % 2\n    pad_w = (2 - w % 2) % 2\n    return np.pad(img, ((0, pad_h), (0, pad_w), (0, 0)), mode='edge')\n\nwith imageio.get_writer(\"judo_episode.mp4\", fps=1, codec=\"libx264\", pixelformat=\"yuv420p\") as writer:\n    for fp in frame_paths:\n        frame = imageio.imread(fp)\n        frame = pad_even(frame)\n        if frame.ndim == 2:\n            frame = np.stack([frame]*3, axis=-1)\n        elif frame.shape[2] == 4:\n            frame = frame[:, :, :3]\n        writer.append_data(frame)\n\nprint(\"MP4 saved to judo_episode.mp4\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T23:08:52.428726Z","iopub.execute_input":"2025-07-16T23:08:52.428991Z","iopub.status.idle":"2025-07-16T23:08:52.563561Z","shell.execute_reply.started":"2025-07-16T23:08:52.428971Z","shell.execute_reply":"2025-07-16T23:08:52.562280Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"As we can see it appears that JB has learned to get both grips and throw, while stripping uke's grips when possible.\n\n*Thanks for watching!! :) :) :)*\n\n*Love,*\n\n*MaryLena \"Merlin\" Bleile*\n*(B.Sc., B.Mus., Ph.D if u care lol)*","metadata":{}},{"cell_type":"markdown","source":"# Appendix: Simulation\n\nMaybe JudoBot just hit a good seed on training. What do the results look like if we train with multiple random seeds? The following code tests by training across 100 random seeds and averaging results. It looks like while we did actually hit a pretty good seed in the above, JudoBot still does learn to outperform the random opponent by a substantial margin. Note also that the \"Game Win Rate\" compares wins to total outcomes, not wins to losses: Since the win rate is lower than the average reward curve, we know that the games JB didn't win are mostly draws (otherwise the -1s from losses would drag the average reward below the game win rate).","metadata":{}},{"cell_type":"code","source":"M = 100\nepisodes=3000\ntest_episodes = 1000\nsmooth = 50\nrewardsMatrix = np.zeros((M,2,episodes+test_episodes - (smooth-1)))\n\n# simple moving average\ndef smooth_arr(arr, k):  \n    return np.convolve(arr, np.ones(k)/k, mode='valid')\nfor m in range(M):\n    agent = Agent(min_eps=0.1,gamma=0.99, alpha=0.5, eps_decay = 0.9995)\n    \n    train(agent, episodes=episodes, verbose=False)\n    \n    agent.eps=0\n    agent.min_eps =0\n    test(agent, episodes=test_episodes, verbose=False)\n    rwd = np.array(agent.rewards)\n    win = np.array(agent.win_flags) \n    rewardsMatrix[m,0,:] = smooth_arr(rwd, smooth)\n    rewardsMatrix[m,1,:] = smooth_arr(win, smooth)\n    #print(\"Monte carlo iteration:\",m,\"\\n\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T23:08:52.566273Z","iopub.execute_input":"2025-07-16T23:08:52.566549Z","iopub.status.idle":"2025-07-16T23:10:58.447819Z","shell.execute_reply.started":"2025-07-16T23:08:52.566524Z","shell.execute_reply":"2025-07-16T23:10:58.446930Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"resultsavg = np.mean(rewardsMatrix, axis=0)\nplt.figure(figsize=(10,4))\nplt.ylim(-1, 1)\nplt.plot(resultsavg[0,:], color = \"black\",label=f'Avg rewards (k={smooth})')\nplt.legend(loc=\"center left\")\nplt.twinx()\nplt.ylim(0, 1)\nplt.plot(resultsavg[1,:], 'b-', label=f'Win rate (k={smooth})')\n#if test_start_iteration is not None:\nplt.axvline(x=episodes+1, color='green', linestyle='--', alpha=0.7, \n                label=f'Testing starts (episode {episodes+1})')\nplt.title('Learning curve')\nplt.xlabel('Episode')\nplt.legend(loc='upper left')\nplt.grid(alpha=.3)\n    #plt.savefig(fname, dpi=150, bbox_inches='tight')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T23:11:08.258156Z","iopub.execute_input":"2025-07-16T23:11:08.258535Z","iopub.status.idle":"2025-07-16T23:11:08.634396Z","shell.execute_reply.started":"2025-07-16T23:11:08.258510Z","shell.execute_reply":"2025-07-16T23:11:08.633234Z"}},"outputs":[],"execution_count":null}]}